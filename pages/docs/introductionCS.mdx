import Image from "next/image";
import Link from "next/link";
import { Steps } from "nextra/components";
import { Callout } from "nextra-theme-docs";

<div className="text-center mt-10">
  <div className="flex justify-center">
    <Image className="-mt-5 animate-bounce" alt="Logotipo Requirements" src='/assets/icons/computerScience.svg'
      width={400} height={400} />
  </div>

  # Introducción a la Informática

</div>

<div className="text-start mt-10">
  <div>
    Bienvenidos a esta fascinante exploración del mundo de la informática, un campo que ha revolucionado cómo vivimos,
    trabajamos y nos comunicamos. La informática, o ciencia de la computación, es una disciplina que abarca teoría,
    diseño,
    desarrollo y aplicación de sistemas de software y hardware. Es un campo dinámico y en constante evolución, donde la
    innovación es la norma y las posibilidades son casi ilimitadas.
  </div>

  ## ¿Qué es la Informática?

  La informática es el estudio sistemático de procesos algorítmicos que describen y transforman información: su teoría,
  análisis, diseño, eficiencia, implementación y aplicación. Es una ciencia que combina aspectos teóricos y prácticos
  para
  comprender y utilizar computadoras de manera efectiva. Abarca una amplia gama de temas, desde el desarrollo de
  algoritmos y estructuras de datos hasta sistemas operativos, inteligencia artificial, ciencia de datos, y más allá.

  Esta disciplina no solo se ocupa de cómo funcionan los sistemas computacionales sino también de cómo se integran en la
  sociedad y afectan nuestro día a día. La informática tiene aplicaciones en casi todas las áreas imaginables: medicina,
  educación, entretenimiento, seguridad, y muchas otras, lo que demuestra su relevancia y omnipresencia en el mundo
  moderno.

  Al adentrarnos en el estudio de la informática, no solo aprenderemos a programar. Desarrollaremos una mentalidad
  computacional, que nos permitirá abordar problemas complejos de manera lógica y estructurada, buscar soluciones
  eficientes y, lo más importante, adaptarnos a los rápidos cambios tecnológicos que caracterizan a nuestro tiempo.

  ## Razones para Estudiar Informática

  El estudio de la informática o ciencia de la computación es esencial por varias razones fundamentales que se aplican
  tanto a la vida personal como profesional de los estudiantes. Este campo no solo abarca el desarrollo y manejo de
  software y hardware, sino que también implica una comprensión profunda de los principios fundamentales que rigen el
  procesamiento de la información y la comunicación. Aquí se exploran las razones clave para sumergirse en este
  apasionante campo de estudio:

  <ul className="mt-5">
    <li>
      <strong>Resolución de Problemas Reales:</strong> La informática brinda las herramientas y técnicas
      necesarias
      para resolver
      problemas complejos que encontramos en la vida cotidiana y en el entorno profesional.
      A través del desarrollo de software, análisis de datos y diseño de sistemas
      informáticos, los estudiantes aprenden a abordar desafíos reales, desde mejorar
      la eficiencia en los procesos de negocio hasta contribuir a la investigación
      científica y tecnológica.
    </li>
    <li>
      <strong>Resolución de Problemas Reales: </strong>
      La informática brinda las herramientas y técnicas necesarias para resolver
      problemas complejos que encontramos en la vida cotidiana y en el entorno profesional.
      A través del desarrollo de software, análisis de datos y diseño de sistemas
      informáticos, los estudiantes aprenden a abordar desafíos reales, desde mejorar
      la eficiencia en los procesos de negocio hasta contribuir a la investigación
      científica y tecnológica.
    </li>
    <li>
      <strong>Base para Innovaciones Futuras: </strong>El mundo de la tecnología
      está en constante evolución, y la informática es la base sobre la cual se
      construyen todas las innovaciones futuras. El conocimiento en este campo
      permite a los estudiantes estar a la vanguardia de la tecnología,
      participar activamente en el desarrollo de nuevas ideas y soluciones
      tecnológicas que podrían transformar la sociedad.
    </li>
    <li>
      <strong>Flexibilidad Profesional y Oportunidades: </strong>Una formación
      en informática abre un amplio espectro de oportunidades laborales en
      diversos sectores. Desde el desarrollo de software y sistemas de
      información hasta la Ciberseguridad, inteligencia artificial y ciencia de
      datos, los graduados pueden elegir entre una amplia gama de carreras que
      están en alta demanda y ofrecen salarios competitivos.
    </li>
    <li>
      <strong>Desarrollo de Habilidades Críticas y Creativas: </strong>Más allá
      de los aspectos técnicos, estudiar informática desarrolla habilidades de
      pensamiento crítico, lógica, y creatividad. Estas habilidades son
      transferibles a cualquier campo y son altamente valoradas por los
      empleadores, ya que permiten a los individuos abordar problemas de manera
      innovadora y eficaz.
    </li>
    <li>
      <strong>Impacto Social y Ético: </strong>La informática tiene un profundo
      impacto en la sociedad, influyendo en cómo vivimos, trabajamos y nos
      comunicamos. Estudiar este campo brinda a los estudiantes una comprensión
      de los aspectos éticos y sociales de la tecnología, preparándolos para
      tomar decisiones responsables que consideren las implicaciones de su
      trabajo en la sociedad .
    </li>
  </ul>

  ## Características Clave de la Informática

  La informática, como campo de estudio y práctica, se distingue por varias características clave que la definen y
  separan
  de otras disciplinas. Estas características no solo delinean el alcance y los objetivos del campo, sino que también
  subrayan su importancia y versatilidad en la resolución de problemas del mundo real. A continuación, se destacan
  algunas
  de las características más relevantes de la informática.

  <ul className="mt-5">
    <li>
      <strong>Interdisciplinariedad: </strong>Una de las características más
      distintivas de la informática es su naturaleza interdisciplinaria. La
      informática se entrelaza y se aplica a una multitud de campos, desde las
      ciencias biológicas y la medicina hasta las artes, la arquitectura, y las
      ciencias sociales. Esta interconexión fomenta enfoques innovadores y
      soluciones creativas a problemas complejos, ampliando el impacto de la
      informática más allá de sus propias fronteras.
    </li>
    <li>
      <strong>Innovación y Evolución Constante: </strong>El campo de la
      informática está en constante evolución, impulsado por la innovación y el
      rápido desarrollo tecnológico. Nuevas teorías, modelos, algoritmos y
      tecnologías emergen regularmente, expandiendo las capacidades y
      aplicaciones de los sistemas computacionales. Esta evolución continua
      requiere que los profesionales y estudiantes se mantengan aprendiendo y
      adaptándose a lo largo de sus carreras.
    </li>
    <li>
      <strong>Pensamiento Algorítmico y Solución de Problemas: </strong>La
      informática pone un fuerte énfasis en el desarrollo del pensamiento
      algorítmico, que es la capacidad de descomponer problemas complejos en
      pasos manejables y definir procedimientos sistemáticos para resolverlos.
      Este enfoque metódico no solo es fundamental para la programación y el
      desarrollo de software, sino que también es una habilidad valiosa en la
      vida cotidiana y en diversas profesiones.
    </li>
    <li>
      <strong>Automatización y Eficiencia : </strong>Una meta central de la
      informática es la automatización de tareas para aumentar la eficiencia y
      la productividad. A través de la creación de software y sistemas
      inteligentes, la informática permite la realización de tareas repetitivas
      o complejas con mayor rapidez y precisión, liberando tiempo y recursos
      humanos para actividades que requieren un mayor nivel de creatividad o
      pensamiento crítico.
    </li>
    <li>
      <strong>Impacto Global y Conectividad: </strong>La informática ha sido un
      motor clave en la globalización y la creación de una sociedad
      interconectada. Internet, las redes sociales, y el comercio electrónico
      son solo algunos ejemplos de cómo la informática ha transformado la manera
      en que comunicamos, trabajamos y hacemos negocios a nivel mundial,
      acercando a las personas y mercados de manera previamente inimaginable.
    </li>
    <li>
      <strong>Ética y Responsabilidad Social: </strong>A medida que la
      informática se integra más profundamente en todos los aspectos de la
      sociedad, surgen importantes consideraciones éticas y de responsabilidad
      social. Los profesionales de la informática deben navegar por cuestiones
      relacionadas con la privacidad, la seguridad, la equidad y el impacto
      ambiental de la tecnología, equilibrando la innovación con el respeto a
      los derechos individuales y el bienestar colectivo.
    </li>
  </ul>

  ## Historia y Evolución de la Informática

  La historia de la informática o ciencia de la computación es rica y variada, extendiéndose desde los orígenes teóricos
  y
  máquinas primitivas hasta la era moderna de movilidad, nube e inteligencia artificial. Es una historia que refleja la
  evolución de la tecnología y cómo esta ha sido modelada por las necesidades, deseos y la imaginación humana.

  <Steps>

    ### Orígenes Teóricos y Máquinas Primitivas

    En los inicios, la informática estaba más relacionada con la matemática y la filosofía que con la tecnología
    electrónica
    que asociamos con el campo hoy. Figuras como Ada Lovelace, quien trabajó en las notas de la Máquina Analítica de
    Charles
    Babbage, son cruciales en esta era. Lovelace es reconocida por su visión del potencial de las computadoras más allá
    del
    cálculo numérico, lo que la lleva a ser considerada como la primera programadora. La Máquina Analítica de Babbage,
    aunque nunca se completó, es un testimonio de las ambiciones tempranas en el campo y muestra el deseo de automatizar
    el
    proceso de cálculo.

    Alan Turing, otro pionero, introdujo el concepto de una "máquina universal" capaz de ejecutar cualquier algoritmo.
    La
    Máquina de Turing, aunque teórica, estableció las bases de lo que se convertiría en la computación moderna y el
    procesamiento de algoritmos.

    ### La Era de las Computadoras Electrónicas

    La Segunda Guerra Mundial catalizó el desarrollo de la informática con la creación de máquinas como Colossus y
    ENIAC.
    Estas máquinas, diseñadas para descifrar códigos y realizar cálculos balísticos, respectivamente, mostraron el
    potencial
    de la tecnología de computación para resolver problemas complejos a una velocidad y escala sin precedentes.

    La invención del transistor y luego del circuito integrado transformó el campo, miniaturizando y abaratando los
    componentes de las computadoras. Esto allanó el camino para la proliferación de las computadoras personales en las
    décadas de 1970 y 1980, haciéndolas accesibles al público en general.

    ### El Auge de la Informática Personal y de Internet

    La introducción de la PC de IBM y la Macintosh de Apple democratizó la informática, introduciendo la era de la
    informática personal. La creación de Internet y el desarrollo del World Wide Web transformaron aún más el campo,
    conectando a las personas de maneras nuevas y revolucionarias y estableciendo una plataforma global para la
    información
    y el comercio.

    ### La Era Moderna: Movilidad, Nube e IA

    Hoy en día, la informática se caracteriza por la omnipresencia de los smartphones, que han hecho de la computación
    una
    experiencia constante en la vida diaria. La computación en la nube ha facilitado el acceso a poderosos recursos
    computacionales y almacenamiento, mientras que la inteligencia artificial y el aprendizaje automático están
    impulsando
    innovaciones en casi todas las industrias.

    ### El Futuro de la Informática

    A medida que la informática continúa evolucionando, se espera que surjan nuevas tecnologías y paradigmas que cambien
    la forma en que interactuamos con la tecnología y el mundo que nos rodea. Desde la computación cuántica y la
    computación neuromórfica hasta la informática ubicua y la computación sostenible, el futuro de la informática
    promete ser emocionante y lleno de posibilidades.

  </Steps>

  <Callout emoji="👀" type="info">
    Desde sus inicios teóricos hasta las aplicaciones prácticas de hoy, la
    informática ha sido una fuerza transformadora en la sociedad. Con cada
    innovación, desde las máquinas mecánicas de Babbage hasta los algoritmos de
    inteligencia artificial de hoy, la informática ha ampliado los límites de lo
    que es posible. Mirando hacia el futuro, continúa siendo un campo de infinitas
    posibilidades y exploración, prometiendo transformar aún más nuestra manera de
    vivir, trabajar y comunicarnos​​.
  </Callout>

  ## El Lenguaje de las Computadoras

  Las computadoras, a diferencia de los humanos, no comprenden palabras, números o imágenes directamente. Su lenguaje es
  binario, compuesto exclusivamente por ceros y unos. Este lenguaje se basa en sistemas de representación que convierten
  la información __desde texto hasta videos__ en datos binarios que las computadoras pueden procesar. La transformación
  de
  información compleja en secuencias binarias permite a las computadoras realizar una amplia gama de tareas, desde
  operaciones matemáticas simples hasta el procesamiento de gráficos complejos y la gestión de comunicaciones en redes.

  ### Origen del Código Binario

  Una forma intuitiva de entender el código binario es pensar en cómo contamos con los dedos, algo que todos hemos hecho
  desde pequeños. Tradicionalmente, usamos un sistema decimal basado en diez dígitos, del 0 al 9, porque tenemos diez
  dedos. Pero ¿qué pasaría si usáramos un sistema más simple, basado solo en dos estados, como "arriba" y "abajo" o
  "extendido" y "no extendido" para cada dedo?

  Imagina que cada uno de tus dedos representa un bit, la unidad más básica de información en computación. En lugar de
  contar hasta diez, podrías contar hasta 31 con una sola mano o hasta 1023 con ambas manos, usando el sistema binario.
  Aquí es donde se vuelve fascinante la relación entre los conceptos básicos de la computación y nuestras actividades
  cotidianas.

  <Callout emoji="📖" type="default">
    **_Contando con una Mano_**

    En el sistema binario, solo tienes dos dígitos: 0 y 1. Cada dedo puede estar en dos estados: abajo (0) o arriba (1).
    Comenzando con todos los dedos abajo, tienes el número cero. Levantando solo el dedo meñique, pasas al número uno
    (00001
    en binario, usando cinco bits para representar los cinco dedos de una mano). Levantando el anillo, tendrías el
    número
    dos (00010 en binario), y con ambos, el tres (00011), para representar el número 4 en binario con tus dedos,
    necesitas levantar el dedo que representa el valor "4" en el
    sistema decimal, que es el dedo medio, y dejar los demás dedos bajados. Esto es porque en binario, el número 4 se
    escribe como "100".

  </Callout>

  Otro ejemplo práctico del código binario es el uso de bombillas. Imagina que cada bombilla es como un bit: encendida
  (1)
  o apagada (0). Con un conjunto de bombillas, puedes representar cualquier número en binario de la misma manera que con
  los dedos.

  <Callout emoji="📖" type="default">
    **_Contando con Bombillas_**

    Si tienes tres bombillas en línea y todas están apagadas, representas el número cero (000 en binario) -> 💡💡💡.
    Encendiendo solo
    la bombilla más a la derecha, representas el número uno (001) -> 💡💡"💡". Encendiendo la bombilla del medio,
    representas el
    número
    dos (010) -> 💡"💡"💡, y con ambas, el tres (011) -> 💡"💡""💡". Añadiendo más bombillas (o bits), puedes
    representar números cada
    vez
    mayores,
    demostrando cómo las computadoras utilizan el binario para representar toda la información, desde simples números
    hasta
    complejas imágenes y sonidos.

  </Callout>

  ### El Código Decimal y los Bits

  Tras entender cómo el código binario puede representar números usando los estados "encendido" y "apagado", es
  fundamental explorar cómo este sistema se relaciona con el código decimal, el sistema numérico que utilizamos en la
  vida
  cotidiana, y el concepto de bits, que son la piedra angular de la informática.

  #### Del Binario al Decimal

  El sistema decimal es base diez, lo que significa que se basa en diez símbolos diferentes: 0, 1, 2, 3, 4, 5, 6, 7, 8,
  y 9. Cada posición en un número decimal representa una potencia de 10, basada en su posición desde la derecha. Por
  ejemplo, en el número 345, el 5 está en la posición de las unidades (10^0), el 4 en la de las decenas (10^1), y el 3
  en
  la de las centenas (10^2). Para convertir un número decimal a binario, se utiliza un proceso similar al de contar con

  <Callout emoji="📖" type="default">
    El código binario, siendo base dos, utiliza un concepto similar pero con solo
    dos símbolos. Cada posición en un número binario representa una potencia de 2.
    Por lo tanto, convertir de binario a decimal implica multiplicar cada bit por
    2 elevado a su posición y sumar los resultados. Por ejemplo, el binario 1101
    se convierte en decimal como sigue: (1×2^3) + (1×2^2) + (0×2^1) + (1×2^0) = 8
    + 4 + 0 + 1 = 13.
  </Callout>

  #### Bits: La Unidad de Medida en Informática

  Un bit, o dígito binario, es la unidad más pequeña de datos en informática y puede tener un valor de 0 o 1. Los bits
  son
  fundamentales porque, en el hardware de las computadoras, cada bit se representa por estados físicamente mensurables,
  como el paso o no paso de electricidad.

  <ul className="mt-5">
    <li>
      <strong>Byte: </strong> Mientras que un solo bit puede representar solo dos
      valores, la agrupación de bits permite representar una gama mucho más amplia
      de valores. Un conjunto de 8 bits forma un byte, permitiendo 256
      combinaciones diferentes (2^8), desde 00000000 hasta 11111111 en binario, o
      0 a 255 en decimal.
    </li>
  </ul>

  #### Representando Más que Números

  Aunque empezamos con números, el código binario se extiende a la representación de letras, símbolos y colores,
  utilizando convenciones estándar. Por ejemplo, en el sistema ASCII, el número decimal 65 (o 01000001 en binario)
  representa la letra "A".

  <ul className="mt-5">
    <li>
      <strong>Colores: </strong> En gráficos por computadora, los colores se
      suelen representar mediante el modelo RGB, donde cada componente de color
      (Rojo, Verde, Azul) se especifica por un byte. Esto permite millones de
      combinaciones de colores, desde 00000000 00000000 00000000 (negro) hasta
      11111111 11111111 11111111 (blanco).
    </li>
    <li>
      <strong>Imágenes y Sonido:</strong> Las imágenes digitales utilizan matrices
      de píxeles, donde cada píxel tiene un valor binario que representa su color.
      Los archivos de audio digital, por otro lado, representan sonidos a través
      de muestras tomadas a intervalos regulares, codificadas en binario.
    </li>
  </ul>

  ## Algoritmos

  El término "algoritmo" se refiere a un conjunto de instrucciones paso a paso diseñadas para realizar una tarea
  específica o resolver un problema determinado. En la informática, los algoritmos son fundamentales porque definen la
  lógica que dirige el funcionamiento del software. Aunque los algoritmos pueden ser tan simples como una receta de
  cocina
  o las instrucciones para montar un mueble, en la tecnología, se implementan a menudo como código que las computadoras
  pueden ejecutar.

  <Callout emoji="📖" type="default">
    Un ejemplo cotidiano de un algoritmo puede ser el proceso de buscar un
    contacto en un teléfono inteligente. En la era pre-digital, esto podría haber
    implicado hojear una agenda o guía telefónica impresa para encontrar el número
    de una persona. Si querías llamar a John Harvard, por ejemplo, empezarías en
    la página uno y pasarías las páginas una a una hasta llegar a la sección "H".
    Este método, aunque efectivo, es ineficiente ya que requiere pasar por muchas
    páginas irrelevantes.
  </Callout>

  ### Mejora con la Tecnología

  Con la introducción de los smartphones, el proceso de buscar un contacto se ha transformado gracias a los algoritmos.
  Al abrir la aplicación de contactos, puedes simplemente empezar a escribir el nombre de la persona en la barra de
  búsqueda.
  La aplicación no solo autocompleta el nombre basándose en las primeras letras que introduces sino que también localiza
  el contacto de manera casi instantánea. Esto es posible gracias a algoritmos de búsqueda eficientes que optimizan cómo
  se almacena y se recupera la información.

  Esta solo es una introducción a algoritmos, más adelante profundizaremos en cómo se diseñan, analizan y optimizan para
  la resolución de problemas en la informática, pero a donde quiero llegar en este punto es para que sirve los
  algoritmos y para ello veremos en el siguiente capitulo, un programa que se llama Scratch en donde veremos como
  empezamos a utilizar nuestra lógica para solucionar un problema es decir diseñaremos un algoritmo
  <Link target="_blank" href="./scratch.mdx" className="text-blue-600">Scratch</Link>
</div>